# ğŸ“Š **Graphs**

A **graph** is a set of a finite number of **vertices** (also called **nodes**) and **edges**, where the edges are the **links between vertices**.
Each edge in a graph connects two distinct nodes.

In mathematics, a graph is a formal representation of a **network**.
Formally:

<pre align="center">
G = (V, E)
</pre>

where:

* **V** = set of vertices
* **E** = set of edges

---

## ğŸ–¼ï¸ Example of a Graph

<div align="center">
  <img src="./images/01.jpg" width="400px"/>

*Figure 9.1: An example of a graph*
</div>

The graph $G = (V, E)$ in **Figure 9.1** can be described as:

* **Vertices (V):**

<pre align="center">
V = {A, B, C, D, E}
</pre>

* **Edges (E):**

<pre align="center">
E = {{A, B}, {A, C}, {B, C}, {B, D}, {C, D}, {D, D}, {B, E}, {D, E}}
</pre>

So,

<pre align="center">
G = (V, E)
</pre>

---

## ğŸ“˜ Important Definitions in Graphs

### ğŸ”¹ Node or Vertex

A **point or node** in a graph is called a **vertex**.<br/>
ğŸ‘‰ In the diagram above, vertices are **A, B, C, D, and E** (represented as dots).

---

### ğŸ”¹ Edge

A **connection between two vertices**.<br/>
ğŸ‘‰ Example: the line connecting **A** and **B**.

---

### ğŸ”¹ Loop

An **edge that starts and ends on the same vertex**.<br/>
ğŸ‘‰ Example: at **D**, the edge returns to itself.

---

### ğŸ”¹ Degree of a Vertex

The **degree** of a vertex is the **total number of edges** incident on it.<br/>
ğŸ‘‰ Example: Vertex **B** has a **degree of 4** in the figure.

---

### ğŸ”¹ Adjacency

Two vertices are **adjacent** if there is an edge between them.<br/>
ğŸ‘‰ Example: **C** is adjacent to **A** (since there is an edge {A, C}).

---

### ğŸ”¹ Path

A **sequence of vertices and edges** connecting two nodes.<br/>
ğŸ‘‰ Example: Path **C â†’ A â†’ B â†’ E** represents a path from **C** to **E**.

---

### ğŸ”¹ Leaf Vertex (Pendant Vertex)

A **vertex with degree = 1**.<br/>
ğŸ‘‰ Example: If a vertex has only one edge connected, it is a **leaf vertex**.

---

# ğŸ”„ **Directed and Undirected Graphs**

Graphs are represented by the **edges** between the **nodes**.
ğŸ‘‰ These connecting edges can be either **directed** or **undirected**.

---

## ğŸ“ Undirected Graph

* If the connecting edges are **undirected**, then the graph is called an **undirected graph**.
* An **undirected graph** simply represents edges as **lines between the nodes**.
* There is no extra information about the relationship between nodes other than the fact that they are connected.

ğŸ–¼ï¸ Example:

<div align="center">
  <img src="./images/02.jpg" width="300px"/>

*Figure 9.2: An example of an undirected graph*
</div>

ğŸ‘‰ In Figure 9.2, we demonstrate an undirected graph of four nodes:

```
V = {A, B, C, D}
```

These nodes are connected using undirected edges.

---

## ğŸ“ Directed Graph

* If the connecting edges are **directed**, then the graph is called a **directed graph**.
* In a **directed graph**, edges provide information about the **direction** of connection.
* An edge **(A, B)** is **not equal** to edge **(B, A)**.
* Directed edges are drawn as **lines with arrows**, showing the direction of flow.

ğŸ–¼ï¸ Example:

<div align="center">
  <img src="./images/03.jpg" width="300px"/>

*Figure 9.3: An example of a directed graph*
</div>

ğŸ‘‰ In Figure 9.3, many nodes are connected using **directed edges**.

* For instance, you can move from **A â†’ B**, but not from **B â†’ A**.

---

## ğŸ“˜ Important Terms in Directed Graphs

### ğŸ”¹ Indegree

The total number of **edges that come into a vertex**.<br/>
ğŸ‘‰ Example: Node **E** has **indegree = 1**, due to edge **C â†’ E**.

---

### ğŸ”¹ Outdegree

The total number of **edges that go out from a vertex**.<br/>
ğŸ‘‰ Example: Node **E** has **outdegree = 2**, because of edges **E â†’ F** and **E â†’ D**.

---

### ğŸ”¹ Isolated Vertex

A vertex with **degree = 0** (no incoming or outgoing edges).<br/>
ğŸ‘‰ Example: Node **G** in Figure 9.3.

---

### ğŸ”¹ Source Vertex

A vertex with **indegree = 0**.<br/>
ğŸ‘‰ Example: Node **A** in Figure 9.3.

---

### ğŸ”¹ Sink Vertex

A vertex with **outdegree = 0**.<br/>
ğŸ‘‰ Example: Node **F** in Figure 9.3.

---

# ğŸ¯ Directed Acyclic Graphs (DAGs)

A **Directed Acyclic Graph (DAG)** is a **directed graph** that contains **no cycles**.

* All edges are directed from one node to another.
* The sequence of edges never forms a **closed loop**.
* A **cycle** in a graph is formed when the starting node of the first edge is equal to the ending node of the last edge.

ğŸ–¼ï¸ Example:

<div align="center">
  <img src="./images/04.jpg" width="350px"/>

*Figure 9.4: An example of a directed acyclic graph*
</div>

ğŸ‘‰ In this DAG:

* All edges are directed.
* There is **no cycle** (no path that starts and ends at the same node).

ğŸ“Œ **Key property:**
If we start on any path from a given node, we will **never end up on the same node again**.

âœ¨ **Applications of DAGs:**

* Job scheduling ğŸ—“ï¸
* Citation graphs ğŸ“š
* Data compression ğŸ“¦

---

# âš–ï¸ Weighted Graphs

A **Weighted Graph** is a graph in which each edge has a **numeric weight** associated with it.

* Can be **directed** or **undirected**.
* Weight may represent **distance**, **cost**, or **any metric** depending on the problem.

ğŸ–¼ï¸ Example:

<div align="center">
  <img src="./images/05.jpg" width="350px"/>

*Figure 9.5: An example of a weighted graph*
</div>

ğŸ‘‰ In this weighted graph:

* **Edge weights** represent distances between nodes.
* We want to travel from **A â†’ D**.

### ğŸ”¹ Possible Paths:

1. **Direct path:**

   * $A \to D$
   * Cost = **40**

2. **Via B and C:**

   * $A \to B \to C \to D$
   * Cost = $5 + 10 + 10 = 25$

### âœ… Best Path:

* Path **A â†’ B â†’ C â†’ D** is **better**, since **25 < 40**.
* Hence, the shortest path is chosen using weights.

---

# ğŸ”— Bipartite Graphs

A **Bipartite Graph** (also called a **Bigraph**) is a **special type of graph** in which:

* All the nodes can be divided into **two disjoint sets**.
* Every edge **always connects a node from one set to a node in the other set**.
* No edge exists **between nodes of the same set**.

ğŸ–¼ï¸ Example:

<div align="center">
  <img src="./images/06.jpg" width="400px"/>
  
*Figure 9.6: An example of a bipartite graph*
</div>

ğŸ‘‰ In this graph:

* The vertices are divided into **two sets**:

  * **Set U = {A, B, C, D}**
  * **Set V = {E, F, G, H}**
* Each edge has **one vertex in U** and **the other vertex in V**.

---

## ğŸ“˜ Key Property of Bipartite Graphs

* **No edge** connects vertices **within the same set**.
* All edges **must connect across the two sets**.

---

## ğŸ—ï¸ Applications of Bipartite Graphs

1. **Applicants and Jobs** ğŸ’¼

   * One set = Applicants
   * Other set = Jobs
   * An edge shows which applicant is eligible for which job.

2. **Football Players and Clubs** âš½

   * One set = Players
   * Other set = Clubs
   * An edge shows if a player has played for a particular club.

---

# ğŸ—‚ï¸ **Graph Representations**

Graph representation techniques define **how we store a graph in memory**.
This includes storing:

* **Vertices (nodes)** ğŸŸ¢
* **Edges (connections)** ğŸ”—
* **Weights (if weighted graph)** âš–ï¸

There are **two common methods** to represent a graph:

1. **Adjacency List** ğŸ“‹
2. **Adjacency Matrix** ğŸ§®

---

## ğŸ“‹ Adjacency List Representation

* Based on a **linked list**.
* For every vertex, we maintain a **list of its neighbors** (adjacent nodes).
* Efficient when the graph is **sparse** (few edges compared to vertices).

ğŸ‘‰ Example:

* If a graph has **200 nodes** but only **100 edges**, then adjacency list is best.
* Saves space because we only store existing edges, not unnecessary zeros.

---

## ğŸ§® Adjacency Matrix Representation

* Based on a **matrix (2D array)**.
* Each **row and column** represent vertices.
* A cell value indicates whether an edge exists between two nodes.

ğŸ‘‰ Example:

* For a graph with **200 nodes**, the matrix will be **200 Ã— 200**.
* Most cells may be **0** if the graph is sparse.

âœ… **Best used when graph is dense** (many edges).
âœ… **Faster lookups** â€“ checking if an edge exists between two vertices is **O(1)**.

---

## âš–ï¸ Choosing Between Them

| Representation       | Best For ğŸ†               | Space Usage ğŸ“¦                         | Lookup Speed â±ï¸ |
| -------------------- | ------------------------- | -------------------------------------- | --------------- |
| **Adjacency List**   | Sparse graphs (few edges) | Less space (only store existing edges) | Slower lookup   |
| **Adjacency Matrix** | Dense graphs (many edges) | More space (matrix always stored)      | Fast lookup     |

---

# ğŸ“‹ **Adjacency Lists**

In an **Adjacency List representation**:

* All the nodes **directly connected** to a node $x$ are listed in its adjacency list.
* The graph is represented by showing the **adjacent list of every vertex**.

ğŸ‘‰ Example Graph:

<div align="center">
  <img src="./images/07.jpg" alt="" width="350px"/>

*Figure 9.7: A sample graph of five nodes*
</div>

Here:

* **A** is adjacent to **B** and **C**.
* **B** is adjacent to **E, C, A**, etc.

---

## ğŸ”— Adjacency List Representation

A **linked list** can be used to implement adjacency lists.

* We need as many **linked lists** as there are **nodes**.
* At each index, we store the **adjacent vertices** of that node.

ğŸ‘‰ Example Adjacency List for Figure 9.7:

<div align="center">
  <img src="./images/08.jpg" alt="" width="350px"/>

*Figure 9.8 : Adjacency list for the graph shown in Figure 9.7*
</div>

---

### ğŸ–¥ï¸ Python Dictionary Implementation

In Python, instead of linked lists, we often use **dictionaries** to represent adjacency lists (since they allow easy keyâ€“value storage).

```python
# Graph represented as adjacency list using dictionary
graph = dict()

graph['A'] = ['B', 'C']
graph['B'] = ['E', 'C', 'A']
graph['C'] = ['A', 'B', 'E', 'F']
graph['E'] = ['B', 'C']
graph['F'] = ['C']
```

---

### ğŸ” Explanation (Line by Line)

1. `graph = dict()`

   * Creates an empty dictionary called **graph**.
   * Each key will represent a **vertex**.
   * Each value will be a **list of adjacent vertices**.

2. `graph['A'] = ['B', 'C']`

   * Vertex **A** has neighbors **B** and **C**.

3. `graph['B'] = ['E', 'C', 'A']`

   * Vertex **B** has neighbors **E, C, and A**.

4. `graph['C'] = ['A', 'B', 'E', 'F']`

   * Vertex **C** has neighbors **A, B, E, and F**.

5. `graph['E'] = ['B', 'C']`

   * Vertex **E** has neighbors **B and C**.

6. `graph['F'] = ['C']`

   * Vertex **F** has only one neighbor: **C**.

---

## âœ… Advantages of Adjacency List

* Saves space when the graph is **sparse**.
* Easy to **add or delete nodes/edges**.

## âš ï¸ Disadvantage

* Checking if a particular edge exists can be **slow** compared to adjacency matrix.

---

# ğŸ§® **Adjacency Matrix**

Another approach to represent a graph is by using an **Adjacency Matrix**.

* The graph is represented using a **matrix (V Ã— V)**, where **V = number of vertices**.
* Each cell in the matrix shows whether there is an **edge** between two vertices:

  * `1` â†’ edge exists
  * `0` â†’ edge does not exist
* The adjacency matrix is essentially a **2D array**.

---

## ğŸ“ Example
<div align="center">
  <img src="./images/09.jpg" alt="" width="400px"/>

*Figure 9.9: A sample graph and its adjacency matrix*
</div>

ğŸ‘‰ The graph has **vertices**: A, B, C, E, F

ğŸ‘‰ The corresponding adjacency matrix is:

|       | A | B | C | E | F |
| ----- | - | - | - | - | - |
| **A** | 0 | 1 | 1 | 0 | 0 |
| **B** | 1 | 0 | 0 | 1 | 0 |
| **C** | 1 | 1 | 0 | 1 | 1 |
| **E** | 0 | 1 | 1 | 0 | 0 |
| **F** | 0 | 0 | 1 | 0 | 0 |

---

## ğŸ–¥ï¸ Python Implementation

We will now implement the adjacency matrix step by step using Python.

### 1ï¸âƒ£ Step 1: Graph Representation (Adjacency List in Dictionary Form)

```python
# Graph represented as adjacency list
graph = dict()
graph['A'] = ['B', 'C']
graph['B'] = ['E', 'C', 'A']
graph['C'] = ['A', 'B', 'E', 'F']
graph['E'] = ['B', 'C']
graph['F'] = ['C']
```

âœ”ï¸ Here, the **keys** represent vertices (A, B, C, E, F).<br/>
âœ”ï¸ The **values** are lists of adjacent vertices.

---

### 2ï¸âƒ£ Step 2: Extract Vertices

```python
# Extract vertices and sort them
matrix_elements = sorted(graph.keys())
cols = rows = len(matrix_elements)
```

âœ”ï¸ `matrix_elements` = `['A', 'B', 'C', 'E', 'F']`<br/>
âœ”ï¸ Number of rows = columns = `5` (since 5 vertices).

---

### 3ï¸âƒ£ Step 3: Initialize Empty Matrix

```python
# Create empty adjacency matrix (filled with 0s)
adjacency_matrix = [[0 for x in range(rows)] for y in range(cols)]
edges_list = []
```

âœ”ï¸ `adjacency_matrix` will be a 5Ã—5 matrix filled with zeros initially.<br/>
âœ”ï¸ Example:

```
[0, 0, 0, 0, 0]
[0, 0, 0, 0, 0]
[0, 0, 0, 0, 0]
[0, 0, 0, 0, 0]
[0, 0, 0, 0, 0]
```

âœ”ï¸ `edges_list` will store edges like `('A', 'B')`.

---

### 4ï¸âƒ£ Step 4: Build Edge List

```python
for key in matrix_elements:
    for neighbor in graph[key]:
        edges_list.append((key, neighbor))
print(edges_list)
```

âœ”ï¸ This creates a list of all edges.<br/>
âœ”ï¸ Output:

```
[('A', 'B'), ('A', 'C'), 
 ('B', 'E'), ('B', 'C'), ('B', 'A'), 
 ('C', 'A'), ('C', 'B'), ('C', 'E'), ('C', 'F'), 
 ('E', 'B'), ('E', 'C'), 
 ('F', 'C')]
```

---

### 5ï¸âƒ£ Step 5: Fill the Adjacency Matrix

```python
for edge in edges_list:
    index_of_first_vertex = matrix_elements.index(edge[0])
    index_of_second_vertex = matrix_elements.index(edge[1])
    adjacency_matrix[index_of_first_vertex][index_of_second_vertex] = 1
```

âœ”ï¸ For each edge `(u, v)`, we find their **indices** in `matrix_elements` and set the matrix cell to `1`.

---

### 6ï¸âƒ£ Final Output Matrix

```python
print(adjacency_matrix)
```

âœ”ï¸ Output:

```
[0, 1, 1, 0, 0]
[1, 0, 0, 1, 0]
[1, 1, 0, 1, 1]
[0, 1, 1, 0, 0]
[0, 0, 1, 0, 0]
```

This corresponds exactly to the adjacency matrix shown in Figure 9.9 âœ…

---

## âœ… Advantages of Adjacency Matrix

* Very **fast lookup** for checking if an edge exists (`O(1)` time).
* Useful in **dense graphs** (many edges).
* Widely used in **routing tables, navigation systems, transport networks**.

## âš ï¸ Disadvantages

* **Consumes more space** (O(VÂ²)), even if graph is sparse.
* **Adding/deleting vertices** is difficult compared to adjacency list.

---

# ğŸ“Š **Graph Traversals**

## ğŸ” What is Graph Traversal?

A **graph traversal** means to **visit all the vertices (nodes)** of the graph while keeping track of:

* âœ… Which vertices have already been **visited**
* âŒ Which vertices have **not been visited yet**

ğŸ‘‰ A graph traversal algorithm is considered **efficient** if it can traverse all the nodes of the graph in the **minimum possible time**.

---

## ğŸŒ³ Graph Traversal vs Tree Traversal

Graph traversal is also called a **graph search algorithm**. It is quite similar to **tree traversal algorithms** such as:

* Preorder traversal
* Inorder traversal
* Postorder traversal
* Level order traversal

ğŸ“Œ Just like tree traversal, in a graph traversal we:

1. Start from a **specific node**
2. Traverse through **edges** to reach all other nodes

---

## ğŸ›¤ï¸ Common Strategy of Graph Traversal

The main strategy is:

1. **Follow a path** until a **dead end** is reached
2. **Backtrack** (move back) until we find an **alternative path**
3. Continue the process until all nodes are visited

Alternatively, we can **iteratively move** from one node to another until the **whole graph (or part of it)** is traversed.

---

## ğŸ¯ Importance of Graph Traversal Algorithms

Graph traversal algorithms are very important for solving **fundamental problems** such as:

* ğŸš¶ Determining how to get from **one vertex to another**
* ğŸ“ Comparing **different paths** from **Node A to Node B**
* ğŸ›£ï¸ Finding the **shortest route** from one city to another in a **network of cities**

---

## ğŸ§® Types of Graph Traversal Algorithms

There are **two important graph traversal algorithms**:

1. **Breadth-First Search (BFS)** ğŸ”„

   * Traverses the graph **level by level**
   * Uses a **queue** data structure

2. **Depth-First Search (DFS)** ğŸ”‚

   * Traverses the graph by going **deep into one path first**
   * Uses a **stack** (or recursion)

---

# ğŸŒ **Breadth-First Traversal (BFS)**

## ğŸ“Œ Introduction

Breadth-First Search (BFS) works very similarly to a **level-order traversal algorithm** in a tree data structure.

* ğŸ”¹ It visits **level by level**
* ğŸ”¹ Starts at the **root node** (level 0)
* ğŸ”¹ Then visits all nodes at **level 1** (directly connected to root)
* ğŸ”¹ Moves to **level 2** and so on

ğŸ‘‰ This ensures traversal of the graph **breadthwise**.

ğŸ“Œ To manage the traversal order, BFS uses a **Queue (FIFO structure)**.

---

## ğŸ—ï¸ How BFS Works

1. Begin with the **starting node**
2. Visit the node and mark it as **visited**
3. Look at all its **neighbors** (adjacent vertices)
4. Add these neighbors into the **queue**
5. Repeatedly visit the **next node from the queue**
6. Add its unvisited neighbors into the queue
7. Continue until all nodes are visited

âœ… Each node is visited **only once**.

---

## ğŸ–¼ï¸ Example Graph

<div align="center">
  <img src="./images/10.jpg" width="500"/>

**Figure 9.10: A sample graph with Queue & Visited array**
</div>

* Graph has **5 nodes**: `A, B, C, D, E`
* On the right side, we have:

  * **Visited Array** â†’ keeps track of visited nodes
  * **Queue** â†’ helps manage BFS order

---

## ğŸ”µ Step 1: Start with Node A

<div align="center">
  <img src="./images/11.jpg" width="500px"/>

**Figure 9.11: Node A is visited in BFS**
</div>

* Start at **A**
* Mark **A** as visited â†’ `Visited = [A]`
* Add all adjacent nodes of A â†’ `B, C, E` into the **Queue**

ğŸ‘‰ Queue = `[B, C, E]`

---

## ğŸ”µ Step 2: Visit Node B

<div align="center">
  <img src="./images/12.jpg" width="500px"/>

**Figure 9.12: Node B is visited in BFS**
</div>

* Dequeue first element â†’ **B**
* Mark **B** as visited â†’ `Visited = [A, B]`
* Add Bâ€™s unvisited neighbor â†’ **D**

ğŸ‘‰ Queue = `[C, E, D]`

---

## ğŸ”µ Step 3: Visit Node C

<div align="center">
  <img src="./images/13.jpg" width="500px"/>

**Figure 9.13: Node C is visited in BFS**
</div>

* Dequeue â†’ **C**
* Mark **C** as visited â†’ `Visited = [A, B, C]`
* Neighbors of C are already visited or in queue â†’ nothing new added

ğŸ‘‰ Queue = `[E, D]`

---

## ğŸ”µ Step 4: Visit Node E

<div align="center">
  <img src="./images/14.jpg" width="500px"/>

**Figure 9.14: Node E is visited in BFS**
</div>

* Dequeue â†’ **E**
* Mark **E** as visited â†’ `Visited = [A, B, C, E]`
* Neighbors of E are already in visited list â†’ nothing added

ğŸ‘‰ Queue = `[D]`

---

## ğŸ”µ Step 5: Visit Node D

<div align="center">
  <img src="./images/15.jpg" width="500px"/>

**Figure 9.15: Node D is visited in BFS**
</div>

* Dequeue â†’ **D**
* Mark **D** as visited â†’ `Visited = [A, B, C, E, D]`
* No new neighbors left

ğŸ‘‰ Queue = `[]` (empty â†’ traversal complete âœ…)

---

## ğŸ“ Final BFS Traversal Order

ğŸ‘‰ The BFS visits nodes in the order:

```
A â†’ B â†’ C â†’ E â†’ D
```

âš ï¸ Note: The order can vary depending on **how neighbors are enqueued**.
For example: BCE, CEB, CBE, BEC, or ECB are all valid.
In this example, we used **alphabetical order**.

---


# ğŸŒ Breadth-First Search Example (BFS) 

## ğŸ–¼ï¸ Figure 9.16 â€” Undirected Sample Graph

<div align="center">
  <img src="./images/17.jpg" width="500px"/>
</div>

* Vertices: **A, B, C, D, E, F, G, H**
* Undirected edges (from the drawing):

  * A connects to **B, D, G**
  * B connects to **A, F, E**
  * C connects to **F, H**
  * D connects to **F, A**
  * E connects to **B, G**
  * F connects to **B, D, C**
  * G connects to **A, E**
  * H connects to **C**

This matches the **adjacency list** you provided (shown next).

---

## ğŸ—‚ï¸ Adjacency List (as given)

```python
graph = dict()
graph['A'] = ['B', 'G', 'D']

graph['B'] = ['A', 'F', 'E']
graph['C'] = ['F', 'H']
graph['D'] = ['F', 'A']
graph['E'] = ['B', 'G']
graph['F'] = ['B', 'D', 'C']
graph['G'] = ['A', 'E']
graph['H'] = ['C']
```

* This stores the undirected graph in a **dictionary of lists** where each key is a vertex and the list contains its neighbors.

---

## ğŸ” BFS Algorithm (as given)

```python
from collections import deque
def breadth_first_search(graph, root):
    visited_vertices = list()
    graph_queue = deque([root])
    visited_vertices.append(root)
    node = root
    while len(graph_queue) > 0:
        node = graph_queue.popleft()
        adj_nodes = graph[node]
        remaining_elements = set(adj_nodes).difference(set(visited_vertices))
        if len(remaining_elements) > 0:
            for elem in sorted(remaining_elements):
                visited_vertices.append(elem)
                graph_queue.append(elem)
    return visited_vertices
```
---

## ğŸ§  Line-by-Line Explanation (with concepts)

* `from collections import deque`
  Imports **deque**, a double-ended queue with **O(1)** appends and pops from either end (perfect for BFS queue).

* `def breadth_first_search(graph, root):`
  Defines BFS function that takes a graph (adjacency list) and a **start/root** node.

* `visited_vertices = []`
  Keeps the **order** of visited nodes. Using a list allows us to return the traversal sequence.

* `graph_queue = deque([root])`
  Initializes the BFS **queue** with the starting node. Queue enforces **FIFO** behavior.

* `visited_vertices.append(root)`
  Marks the root as **visited** immediately (so we donâ€™t re-enqueue it later).

* `while len(graph_queue) > 0:`
  Process nodes **until the queue empties** (i.e., no frontier left).

* `node = graph_queue.popleft()`
  **Dequeue** the next node to visit (FIFO). This is the current node being expanded.

* `adj_nodes = graph[node]`
  Get all **neighbors** (adjacent vertices) of the current node.

* `remaining_elements = set(adj_nodes).difference(set(visited_vertices))`
  Compute **unvisited neighbors only**.

  * `set(adj_nodes)` = candidates to consider
  * `set(visited_vertices)` = already seen
  * **difference** = neighbors we havenâ€™t visited yet

* `if len(remaining_elements) > 0:`
  Only act if there is at least one unvisited neighbor.

* `for elem in sorted(remaining_elements):`
  Enqueue neighbors in **alphabetical order** (your text explicitly chooses this to keep a consistent traversal).

* `visited_vertices.append(elem)`
  Mark neighbor as visited **at enqueue time** (this version does it here to avoid enqueuing duplicates later).

* `graph_queue.append(elem)`
  Put neighbor into the queue for future expansion.

* `return visited_vertices`
  Return the **BFS traversal order**.

> ğŸ’¡ This strategy guarantees each node is **enqueued once** and **dequeued once**, avoiding duplicates and cycles.

---

## â–¶ï¸ Dry Run (exactly as described) from **A**

Weâ€™ll follow your rule to add neighbors in **alphabetical order**.

### ğŸŸ¦ Initial state (enqueue A, mark A visited)

* **Visited:** `[A]`
* **Queue:** `deque([A])`

---

### ğŸ–¼ï¸ Figure 9.17 â€” Visit A; enqueue B, D, G (alphabetical order)

<div align="center">
  <img src="./images/18.jpg" width="500px"/>
</div>

* Dequeue **A**
* Aâ€™s neighbors: **B, G, D** â†’ unvisited â†’ sort â†’ **B, D, G**
* Enqueue **B, D, G** and mark them visited

**Visited:** `[A, B, D, G]`
**Queue:** `deque([B, D, G])`

---

### ğŸ–¼ï¸ Figure 9.18 â€” Visit B; enqueue E, F

<div align="center">
  <img src="./images/19.jpg" width="500px"/>
</div>

* Dequeue **B**
* Bâ€™s neighbors: **A, F, E**

  * A already visited
  * **E, F** are unvisited â†’ alphabetical â†’ **E, F**
* Enqueue **E, F** and mark them visited

**Visited:** `[A, B, D, G, E, F]`
**Queue:** `deque([D, G, E, F])`

---

### ğŸ§­ Process D, G (no new nodes), thenâ€¦

* **Dequeue D** â†’ neighbors **F, A** (both already visited) â†’ nothing new
  **Queue:** `deque([G, E, F])`
* **Dequeue G** â†’ neighbors **A, E** (A visited, E already in visited) â†’ nothing new
  **Queue:** `deque([E, F])`

---

### ğŸ–¼ï¸ Figure 9.19 â€” Visit E (no new nodes)

<div align="center">
  <img src="./images/20.jpg" width="500px"/>
</div>

* **Dequeue E** â†’ neighbors **B, G** (both already visited) â†’ nothing new

**Visited:** `[A, B, D, G, E, F]`
**Queue:** `deque([F])`

---

### ğŸ–¼ï¸ Figure 9.20 â€” Visit F; enqueue C

<div align="center">
  <img src="./images/21.jpg" width="500px"/>
</div>

* **Dequeue F** â†’ neighbors **B, D, C**

  * B and D visited
  * **C** unvisited â†’ enqueue **C**, mark visited

**Visited:** `[A, B, D, G, E, F, C]`
**Queue:** `deque([C])`

---

### ğŸ–¼ï¸ Figure 9.21 â€” Visit C; enqueue H; then visit H (done)

<div align="center">
  <img src="./images/22.jpg" width="500px"/>
</div>

* **Dequeue C** â†’ neighbors **F, H**

  * F visited
  * **H** unvisited â†’ enqueue **H**, mark visited
    **Queue:** `deque([H])`
* **Dequeue H** â†’ neighbor **C** (already visited) â†’ nothing new
  **Queue:** `deque([])` â†’ **empty â‡’ traversal complete**

---

## âœ… Output Sequence (as you stated)

When we run:

```python
print(breadth_first_search(graph, 'A'))
```

We get:

```python
['A', 'B', 'D', 'G', 'E', 'F', 'C', 'H']
```

This exactly matches the order illustrated across Figures **9.17 â†’ 9.21**.

---

## ğŸ§© Why the Order Can Differ

BFS guarantees **level-by-level** visitation, but **within the same level**, the order depends on **how neighbors are enqueued**.

* Here, we purposely **sort** neighbors (alphabetical) to keep the order deterministic.
* If you changed the neighbor ordering (e.g., inserted as they appear in the adjacency list), the order might differ but would **still be a valid BFS**.

---

## â±ï¸ Time Complexity (as given, with reasoning)

* Every vertex is **enqueued once** and **dequeued once** â†’ total queue operations cost **O(|V|)** because each enqueue/dequeue is **O(1)** with `deque`.
* For each vertex, we **scan its adjacency list** exactly once overall â†’ total is **O(|E|)** across all vertices.
* **Total time:** **O(|V| + |E|)**
* **Space:** O(|V|) for `visited_vertices` and up to O(|V|) for the queue in the worst case.

---

## ğŸŒ Real-World Applications of BFS (as provided)

* **Shortest path in unweighted graphs**: Finds minimal number of edges from a source to any node.
* **Web crawling**: Crawl pages **level by level** from a seed page, maintaining **indexed layers** and a **closed list** of visited URLs.
* **Navigation systems**: Quickly fetch **neighboring locations** from a graph of places/roads to explore reachable areas level-wise.

---

## ğŸ§ª Minimal Reproducible Script (complete)

> This is a single, runnable snippet that includes your graph, the BFS, and the print callâ€”using the corrected identifier `visited_vertices`:

```python
from collections import deque

graph = dict()
graph['A'] = ['B', 'G', 'D']

graph['B'] = ['A', 'F', 'E']
graph['C'] = ['F', 'H']
graph['D'] = ['F', 'A']
graph['E'] = ['B', 'G']
graph['F'] = ['B', 'D', 'C']
graph['G'] = ['A', 'E']
graph['H'] = ['C']

def breadth_first_search(graph, root):
    visited_vertices = []
    graph_queue = deque([root])
    visited_vertices.append(root)
    while len(graph_queue) > 0:
        node = graph_queue.popleft()
        adj_nodes = graph[node]
        remaining_elements = set(adj_nodes).difference(set(visited_vertices))
        if len(remaining_elements) > 0:
            for elem in sorted(remaining_elements):
                visited_vertices.append(elem)
                graph_queue.append(elem)
    return visited_vertices

print(breadth_first_search(graph, 'A'))
# Expected: ['A', 'B', 'D', 'G', 'E', 'F', 'C', 'H']
```

---


# ğŸŒŠ **Depth-First Search (DFS)**

## ğŸ” What is DFS?

**Depth-First Search (DFS)** (also called depth-first traversal) traverses a graph similar to **preorder traversal** in trees:

* **Child nodes are visited before sibling nodes.**
* We **start with the root node** â†’ visit it â†’ then explore its **adjacent neighbors**.
* If the neighbor is **unvisited**, go deeper along that path.
* If the neighbor is **already visited**, **backtrack** to the previous node using a stack.
* Once all neighbors are visited and the stack is empty, the traversal ends.

---

## ğŸ§© Example Graph (Figure 9.22)

<div align="center">
  <img src="./images/22.jpg" width="500"/>

**Figure 9.22:** *An example graph for understanding the DFS algorithm.*
</div>

We start from **A** and explore neighbors in **alphabetical order**.

---

## ğŸ¾ Step-by-Step Traversal (Figures 9.23 â†’ 9.27)

> Notation: **Visited** = nodes visited so far; **Stack (top â†‘)** = current backtracking helper.

---

### â–¶ï¸ Figure 9.23 â€” Visit **A**, then **B**

<div align="center">
  <img src="./images/23.jpg" width="500px"/>
</div>


* Start at **A** â†’ mark it visited.

  * **Visited:** `A`
  * **Stack (top â†‘):** `B` (first neighbor of A is chosen â†’ **B**)

* Visit **B**. Its only neighbor is **A**, which is already visited â†’ backtrack.

  * Back at **A**, the next unvisited neighbor is **S**.

---

### â–¶ï¸ Figure 9.24 â€” Visit **S**, then **C**

<div align="center">
  <img src="./images/24.jpg" width="500px"/>
</div>

* Visit **S**. Neighbors of S: **C, G** â†’ choose **C** (alphabetical).
* Visit **C**.

  * **Visited:** `A, B, S, C`
  * **Stack top:** `D` (next deeper path).

---

### â–¶ï¸ Figure 9.25 â€” Visit **D**, then **E**

<div align="center">
  <img src="./images/25.jpg" width="500px"/>
</div>

* Visit **D**. It has no new unvisited neighbors â†’ backtrack to **C**.
* Visit **E** next from Câ€™s neighbors.

  * **Visited:** `A, B, S, C, D, E`
  * **Stack top:** `H`.

---

### â–¶ï¸ Figure 9.26 â€” Visit **H**, then **G**

<div align="center">
  <img src="./images/26.jpg" width="500px"/>
</div>

* From **E**, visit **H**.
* From **H**, visit **G**.

  * **Visited:** `A, B, S, C, D, E, H, G`
  * **Stack top:** `F`.

---

### â–¶ï¸ Figure 9.27 â€” Finally visit **F**

<div align="center">
  <img src="./images/27.jpg" width="500px"/>
</div>

* From **G**, visit **F**.
* All neighbors are visited now.
* Stack becomes empty â†’ traversal ends.

**âœ… Final Traversal Order:** `A-B-S-C-D-E-H-G-F`

---

## ğŸ§­ Adjacency List (Graph Representation)

```python
graph = dict()
graph['A'] = ['B', 'S']
graph['B'] = ['A']
graph['S'] = ['A','G','C']
graph['D'] = ['C']
graph['G'] = ['S','F','H']
graph['H'] = ['G','E']
graph['E'] = ['C','H']
graph['F'] = ['C','G']
graph['C'] = ['D','S','E','F']
```

---

## ğŸ§‘â€ğŸ’» DFS Implementation in Python

```python
def depth_first_search(graph, root):
    visited_vertices = list()
    graph_stack = list()
    graph_stack.append(root)
    node = root
    while graph_stack:
        if node not in visited_vertices:
            visited_vertices.append(node)
        adj_nodes = graph[node]
        if set(adj_nodes).issubset(set(visited_vertices)):
            graph_stack.pop()
            if len(graph_stack) > 0:
                node = graph_stack[-1]
            continue
        else:
            remaining_elements = set(adj_nodes).difference(set(visited_vertices))
            first_adj_node = sorted(remaining_elements)[0]
            graph_stack.append(first_adj_node)
            node = first_adj_node
    return visited_vertices
```

---

## ğŸ§  Line-by-Line Explanation

1. **Function Definition**

   ```python
   def depth_first_search(graph, root):
   ```

   Define DFS function with an adjacency list `graph` and a starting node `root`.

2. **Visited List & Stack Initialization**

   ```python
   visited_vertices = list()
   graph_stack = list()
   graph_stack.append(root)
   node = root
   ```

   * `visited_vertices`: stores visited nodes in order.
   * `graph_stack`: simulates the call stack.
   * Push `root` to stack.
   * Set current `node` to root.

3. **Traversal Loop**

   ```python
   while graph_stack:
   ```

   Continue while stack is not empty.

4. **Visit Node if New**

   ```python
   if node not in visited_vertices:
       visited_vertices.append(node)
   ```

   If the node is not already visited â†’ mark it visited.

5. **Check Neighbors**

   ```python
   adj_nodes = graph[node]
   if set(adj_nodes).issubset(set(visited_vertices)):
   ```

   If **all neighbors** are already visited â†’ dead end.

6. **Backtrack**

   ```python
   graph_stack.pop()
   if len(graph_stack) > 0:
       node = graph_stack[-1]
   continue
   ```

   Pop the stack and move back to the previous node.

7. **Otherwise Go Deeper**

   ```python
   remaining_elements = set(adj_nodes).difference(set(visited_vertices))
   first_adj_node = sorted(remaining_elements)[0]
   graph_stack.append(first_adj_node)
   node = first_adj_node
   ```

   * Compute unvisited neighbors.
   * Pick the alphabetically smallest one.
   * Push it onto the stack and make it the new current node.

8. **End**

   ```python
   return visited_vertices
   ```

   When stack empties, return the complete traversal order.

---

## ğŸ§ª Dry-Run of the Code (Alphabetical Neighbors)

| Step | Action                          | Visited                   | Stack               |
| ---- | ------------------------------- | ------------------------- | ------------------- |
| 1    | Start at **A**                  | A                         | A                   |
| 2    | Visit **B**                     | A, B                      | A, B                |
| 3    | Backtrack to **A**, go to **S** | A, B, S                   | A, S                |
| 4    | Visit **C**                     | A, B, S, C                | A, S, C             |
| 5    | Visit **D**                     | A, B, S, C, D             | A, S, C, D          |
| 6    | Backtrack to C â†’ Visit **E**    | A, B, S, C, D, E          | A, S, C, E          |
| 7    | Visit **H**                     | A, B, S, C, D, E, H       | A, S, C, E, H       |
| 8    | Visit **G**                     | A, B, S, C, D, E, H, G    | A, S, C, E, H, G    |
| 9    | Visit **F**                     | A, B, S, C, D, E, H, G, F | A, S, C, E, H, G, F |
| 10   | Backtrack until stack is empty  | Done                      | âˆ…                   |

**Final Output:** `A-B-S-C-D-E-H-G-F`

---

## â±ï¸ Time Complexity

* **Adjacency List:** `O(V + E)`
  Each vertex and edge is processed once.
* **Adjacency Matrix:** `O(VÂ²)`
  Neighbor lookups are slower since the entire row must be scanned.

---

## ğŸ§° Applications of DFS

* ğŸ§© Solving **mazes**
* ğŸ”— Finding **connected components** in graphs
* â™»ï¸ Detecting **cycles** in graphs
* ğŸŒ‰ Identifying **bridges** (critical connections)
* ğŸ“Š Advanced algorithms (topological order, discovery times)

---

# ğŸŒ³ **Minimum Spanning Tree (MST) and Graph Methods**

## ğŸ“Œ Other Useful Graph Methods

Graphs are widely used when we need to **find paths between two nodes**. Depending on the situation:

* ğŸ”¹ Sometimes we need to find **all possible paths**.
* ğŸ”¹ Sometimes we only need the **shortest path**.
* ğŸ”¹ In **routing applications**, we usually determine the shortest path between source and destination.
<br/>

ğŸ‘‰ For **unweighted graphs**, the shortest path = the path with the **least number of edges**.<br/>
ğŸ‘‰ For **weighted graphs**, the shortest path = the path with the **lowest total weight**.

In some cases, we may also need to find the **longest path** or the **shortest path** using different algorithms such as the **Minimum Spanning Tree (MST)**.

---

## ğŸŒ³ Minimum Spanning Tree (MST)

### ğŸ“– Definition

A **Minimum Spanning Tree (MST)** is:

* A **subset of edges** from a connected weighted graph.
* Connects **all nodes** of the graph.
* Has the **lowest possible total edge weight**.
* âŒ No cycle is allowed.

Formally:
Given a connected graph **G = (V, E)** with real-valued edge weights,
an MST is a subgraph with a subset of edges **T** such that:

* The **sum of edge weights** is minimum.
* The graph has **no cycles**.

ğŸ”¹ There may be multiple spanning trees, but the **Minimum Spanning Tree** has the **least total cost**.

---

<div align="center">
  <img src="./images/28.jpg" width="600px"/>

*Figure 9.28: A sample graph with the corresponding Minimum Spanning Tree*
</div>


## ğŸ–¼ï¸ Example (Figure 9.28)

On the **left side**, we have a weighted graph.
On the **right side**, we see its MST.

* All nodes are connected.
* Only a subset of edges are chosen.
* The **total weight = 1 + 4 + 2 + 4 + 5 = 16** (minimum possible).

---

## âš™ï¸ Algorithm Used: Kruskalâ€™s Algorithm

Kruskalâ€™s Algorithm is one of the most common ways to construct an MST.

### ğŸ”‘ Rules

1. Start with the edge with the **smallest weight**.
2. If adding it does **not create a cycle**, include it.
3. Repeat until **all nodes are connected**.

---

## ğŸ“Š Left Side Graph Details

* **Nodes**: A, B, C, E, F, H
* **Edge Weights**:

  * Bâ€“F = 1
  * Aâ€“F = 2
  * Bâ€“A = 3
  * Bâ€“E = 4
  * Eâ€“A = 4
  * Aâ€“C = 4
  * Câ€“H = 5
  * Aâ€“H = 7

---

## ğŸªœ Steps to Build MST (Using Kruskalâ€™s Algorithm)

1. **Smallest edge**: Bâ€“F = 1 â†’ âœ… Take it (no cycle).
2. Next: Aâ€“F = 2 â†’ âœ… Take it (Bâ€“Fâ€“A are now connected).
3. Next: Bâ€“A = 3 â†’ âŒ Skip (forms cycle Bâ€“Fâ€“Aâ€“B).
4. Next: Bâ€“E = 4 â†’ âœ… Take it (E is now connected).
5. Next: Eâ€“A = 4 â†’ âŒ Skip (forms cycle Bâ€“Eâ€“Aâ€“Fâ€“B).
6. Next: Aâ€“C = 4 â†’ âœ… Take it (C is now connected).
7. Next: Câ€“H = 5 â†’ âœ… Take it (H is now connected).
8. Last: Aâ€“H = 7 â†’ âŒ Skip (all nodes are already connected).

---

## âœ… Final MST Edges

* Bâ€“F (1)
* Aâ€“F (2)
* Bâ€“E (4)
* Aâ€“C (4)
* Câ€“H (5)

ğŸ‘‰ These exactly match the edges shown in the right-side MST diagram.

---

## ğŸŒ Real-World Applications of MST

MST is widely used in:

* ğŸ›£ï¸ Road network design (minimizing road congestion)
* âš¡ Electric cable distribution networks
* ğŸ’§ Water/hydraulic pipe networks
* ğŸ“¡ Communication networks
* ğŸ“Š Cluster analysis in data science

---

# ğŸŒ‰ **Kruskalâ€™s Minimum Spanning Tree (MST)**

## ğŸ“– Introduction
Kruskalâ€™s algorithm is a **greedy approach** for finding a **Minimum Spanning Tree (MST)** in a **connected, weighted, undirected graph**.  

- It starts with **all vertices separate** (like each one is its own small tree).  
- Then, it repeatedly adds the **smallest edge** that **does not form a cycle**.  
- The process continues until **all vertices are connected** into one tree with the minimum total weight.  

â±ï¸ **Time Complexity**: `O(E log E)` (or equivalently `O(E log V)`), because sorting the edges dominates the runtime.

---

## ğŸ–¼ï¸ Visual Walkthrough of Example

### **Step 1 â†’ Figure 9.29**
<div align="center">
  <img src="./images/29.jpg" width="600px"/>

  **Figure 9.29**
</div>
 
We begin by selecting the **smallest edge** in the graph.  
- Smallest edge weight = **1**.  
- This edge is included in MST âœ… (no cycle possible).  

---

### **Step 2 â†’ Figure 9.30**
<div align="center">
  <img src="./images/30.jpg" width="600px"/>

  **Figure 9.30**
</div>

Next smallest edges are **2** and **3**.  
- Edge (weight 2) â†’ added âœ… (no cycle).  
- Edge (weight 3) â†’ added âœ… (no cycle).  

Now MST has edges {1, 2, 3}.  

---

### **Step 3 â†’ Figure 9.31**
<div align="center">
  <img src="./images/31.jpg" width="600px"/>

  **Figure 9.31**
</div>
 
Next smallest edges are **4** and **5**.  
- Edge (weight 4) â†’ added âœ….  
- Edge (weight 5) â†’ added âœ….  

MST now contains {1, 2, 3, 4, 5}.  

---

### **Step 4 â†’ Figure 9.32**
<div align="center">
  <img src="./images/32.jpg" width="600px"/>

  **Figure 9.32**
</div>

Next smallest edge is **6**.  
- Adding weight 6 â†’ âœ… valid (no cycle).  

Now MST = {1, 2, 3, 4, 5, 6}.  

ğŸ‘‰ The next edges are **7, 8, 9**, but all would **form a cycle**, so âŒ we skip them.  

- Finally, we add edge **10** â†’ âœ… valid.  

Now MST = {1, 2, 3, 4, 5, 6, 10}.  

---

### **Step 5 â†’ Figure 9.33**
<div align="center">
  <img src="./images/33.jpg" width="400px"/>

  **Figure 9.33**
</div>

This is the **final MST** created by Kruskalâ€™s algorithm.  

âœ… MST edges: {1, 2, 3, 4, 5, 6, 10}  
âœ… MST weight = 1 + 2 + 3 + 4 + 5 + 6 + 10 = **31**  

---

## ğŸªœ Algorithm Steps (Formal)

1. Initialize an empty MST **M = âˆ…**.  
2. Sort all edges by weight.  
3. For each edge `(u,v,w)` in sorted order:  
   - If `u` and `v` are in **different sets**, add `(u,v,w)` to MST.  
   - If theyâ€™re in the **same set**, skip (to avoid cycles).  
4. Stop when MST has **Vâˆ’1 edges** (where V = number of vertices).  

---


